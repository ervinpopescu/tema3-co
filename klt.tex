\documentclass[12pt]{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{babel}
\usepackage{caption}
\usepackage{color}
\usepackage{float}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{physics}
\captionsetup{justification=centering}
\author{Ervin Popescu}
\title{KLT vs FT}
\date{}


\makeatletter
% detach \eqref and \tag making
\renewcommand{\eqref}[1]{\textup{\eqreftagform@{\ref{#1}}}}
\let\eqreftagform@\tagform@\def\tagform@#1{
  \maketag@@@{\color{red} (\ignorespaces#1\unskip\@@italiccorr)}
}
\makeatother
\begin{document}
\maketitle
\section*{Abstract}
In spite of its significant advantages, the KLT has not replaced FT yet.\@ In particular, associ-ated complexity and, thus, the computational burden still speak against KLT and in fact favor classical FFT.\@ The Fourier Transform has its fast, numerical implementation called Fast Fourier Transform with a complexity of \(O(n\times\log(n))\) (i.e.\ \(n\times\log(n)\) addition/multipli-cation operations on data of length n).
The complexity of the numerical implementation of the KLT is much higher — \(O(n^2)\).
The underlying reason for this difference is that the FFT uses a predefined set of orthogonal functions (sines and cosines), 
whereas the KLT looks for the best representation of the orthogonal function for each individual signal.\@ A comparative summary of the characterizations is presented in~\ref{table:1}.
\begin{table}[H]
	\centering
	\begin{tabular}{ |c | c | c| }
	\hline
	\ & Fast Fourier Transform & Karhunen-Loeve Transform \\
	\hline
	Decomposition functions & Sines and cosines & Any orthonormal functions \\ 
	\hline
	Type of signal analysis & Deterministic & Deterministic and stochastic \\
	\hline
	Optimal frequency range & Narrowband signals & Narrowband and wideband signals \\
	\hline
	Potential to detect feeble signal & Small & High \\
	\hline
	Complexity & $O(n\times\log(n))$ & $0(n^2)$ \\
	\hline
	\end{tabular}
	\caption{Comparison of selected characteristics of \\the Fast Fourier Transform and Karhunen-Loeve Transform}
	\label{table:1}
\end{table}
% \pagebreak
\section*{KLT and FFT --- Analogies and Differences}
The Karhunen-Loeve Transform and the Fourier Transform have many analogies but also important differences.\@ To gain further insight into the mathematical characteristics of each of them, let us compare the equations for the Fourier series of a deterministic periodic signal \(x(t)\) and its analogous KL expansion of a stochastic process of the signal \(X(t)\) are compared.\@ (Stochastic variables are denoted by capitals).

As is well known, any periodic signal can be expressed in terms of a Fourier series as follows:
\begin{equation}
	x(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_n\cos({\omega_n}t)+b_n\sin({\omega_n}t)]
\end{equation}\label{eq:1} 
where the angular frequencies are defined by \(w = n(2\pi/ T)\) with the period of the signal being \(T=t_2-t_1\).

This equation defines a deterministic signal \(x(t)\) as a sum of sines and cosines that have an amplitude equal to the corresponding coefficients \(a_n\) and \(b_n\).\@ The norm of the square of these coefficients gives information about the power at the correspondent to the coefficients frequency.\@ By definition, the FFT basis functions are extended between minus infinity and infinity, which allows the calculation of the exact amplitudes of the functions for each frequency.

The coefficients \(a_n\) and \(b_n\) of the Fourier series are defined by the following formulas:
\begin{equation}
	a_n=\frac{2}{T}\int_{t_1}^{t_2}x(t)\cos({\omega_n}t)\,dt
	\label{eq:2}
\end{equation}
\begin{equation}
	b_n=\frac{2}{T}\int_{t_1}^{t_2}x(t)\sin({\omega_n}t)\,dt
	\label{eq:3}
\end{equation}

These are integrated projections of the sine and cosine on the signal.

Applying the KLT methodology to a stochastic process \(X(t)\) over the finite time interval $0 \leq t \leq T$ can be represented by equation (\ref{eq:4}) which shows some analogies to the Fourier series:
\begin{equation}
	X(t)=\sum_{n=1}^{\infty}Z_n\Phi_n(t)
	\label{eq:4}
\end{equation}

The deterministic functions $\Phi_n(t)$ are called eigenvectors or eigenfunctions, while $Z_n$, are random scalar variables.\@ This is a very short equation but the consequences and possibilities standing behind it are enormous.\@ As we can see, this is a generic decomposition in vectorial space using eigenfunctions,
which can have in principle any form.\@ We should mention that, in both the Fourier series and the KL expansion, the eigenfunctions have to be ortho normal, i.e., orthogonal and normalized to one.\@ In effect, these functions are uncorrelated and can be a base of any
signal in infinite dimensional Euclidean space spanned by these functions.

Another important note: the eigenfunctions $\Phi_n(t)$ are to the KL expansion what the set of sines and cosines is to the
Fourier series.\@ However, the eigenfunctions' shape is in principle unknown and adapts to the signal being processed.\@ Also, unlike the Fourier series, the KLT eigenfunctions have a finite support, making the requirement for a periodic signal unnecessary.\@ This is an important advantage of the KL expansion compared to the FT, because the data to be processed usually has a finite duration.

But the most revolutionary aspect of the KL expansion is still to come.

Unlike the FT, the coefficients $Z_n$ of the KL expansion of a stochastic process $X(t)$ are pure random variables.\@ In contrast to $a_n$ and $b_n$ of the Fourier series, the KL coefficients reflect the stochastic nature of the data under analysis.\@ In his work, Maccone proposed computation ofthe random variable $Z_n$, by using a very similar equation as the formulas (\ref{eq:2}) and (\ref{eq:3}):
\begin{equation}
	Z_n=\int_{0}^{T}X(t)\Phi_n(t)\,dt 
	\label{eq:5}
\end{equation}
Similar to the coefficients of the Fourier series, equation (\ref{eq:5}) describes the projection of the processed signal onto eigenfunctions.\@ It is worth highlighting the fact that the integral boundaries, which are finite, cover the entire signal duration $0{\leq}t{\leq}T$; thus, KLT also applies well for non-periodic signals.

We must emphasize that the \textit{variance} of the KL expansion coefficients $Z_n$ is more impor-tant than the coefficients themselves.\@ This variance is called eigenvalue and is denoted $\lambda_n$.

The eigenvalue $\lambda_n$, corresponds to $\Phi_n(t)$ and represents the expected power of the corres-ponding eigenfunction and is significant for the filtering capabilities ofthe KLT, which can be used for detection of feeble signals.\@ Theoretically, what Maccone demonstrates in his article is that a signal containing only pure noise is characterized by KLT eigenvalues, which are uniformly distributed and equal to one.\@ This is true for a continuous signal only.\@ Consequently, we can already state that eigenvalues larger than one can identify that a corresponding eigenfunction is correlating better with the hidden signal than with the remaining noise.

So, how does one compute the eigenvalues and eigenfunctions of a signal? The KLT computes the covariance of a processed signal which is then used to find its eigenvalues and eigenvectors.\@ The follow
ing equations are derived in Maccone's article, with (\ref{eq:6}) providing a fundamental equation to compute the unknown eigenvalues and eigenfunctions:
\begin{equation}
	\int_{0}^{T}E\{X(t_1)X(t_2)\}\Phi_n(t)\,dt_1=\lambda_n\Phi_n(t_2)
	\label{eq:6}
\end{equation}
Equation (\ref{eq:6}) is analytically derived from the KL expansion equation (\ref{eq:4}).\@ In this equation $E\{X(t_1)X(t_2)\}$ represents the autocorrelation of a stochastic process $X(t)$ at instants $t_1$ and $t_2$.\@ This is the only known variable of this equation.\@ The linear autocorrelation function is calculated directly from the processed signal.

Thanks to this, the eigenfunction characterize the structure of a processed signal at the same time that it becomes sensitive to the signal's harmonic behavior.\@ This is the main advantage of the KLT over the FT.\@ Because of this sensitivity it is now possible to identify eigenfunctions related to the non-stochastic content of the signal.\@ As mentioned earlier, a parameter that allows this identification is the eigenvalue.

During simulations for which results are presented later in this article, discrete signals were processed and the length of the autocorrelation was finite.\@ Under these conditions, the eigenvalues of a noise-only signal converge to one and are equal to one on average.

For digital applications we work on sampled signals.\@ So, as usual, replacing the integral by summation brings us from continuous to discrete data, thus:
\begin{equation}
	\label{eq:7}
	\sum_{k=1}^{N}E\{X_kX_l\}{\Phi}_{n_k}{\Delta}t=\lambda_n \Phi_{n_l}
\end{equation}
which is a set of N linear equations with N unknowns; $E\{{X_k}{X_l}\}$ is a Toeplitz autocorrelation matrix of the size NxN, and, finally, ${\Delta}t$ denotes time duration of the sample.
Equation (\ref{eq:7}) is solved with the rules of classical linear algebra.\@ Eigenvalues and eigenvectors can be determined using common methods.\@ This equation can always be solved; however, the only drawback of the KLT resides here.\@ This set of equations carries with it a significant computational burden on the order of $O(N^2)$.\@ Maccone demonstrated the first successful approach to the problem of computation time, which will be discussed later on in this article.

This theoretical introduction leads us to the practical part.\@ Our purpose here was to investi-gate the capabilities of the KLT as applied to weak signal detection, especially those that can be harmful to GNSS signals on the receiver side and are to be detected from far distance.

In order to gain better insight into the detection capabilities offered by the various well-known methodologies, we tested them using the same input data.\@ We structured the tests in three stages.\@ The first example demonstrates how the KLT decomposes a signal and identifies the eigenvalues and eigenfunctions of the data.\@ Next, a narrowband, single sinusoidal signal was selected to check the performance of the KLT.

The final example addresses the wideband signal detection capabilities of the various approa-ches.\@ We carried out the last exercise (or stage) for two kinds of signals: a BPSK (binary phase shift keying) modulated signal, representing a stationary signal to reveal the KLT's limitations on wideband signals (Example 3) and a  sideband chirp, which represents Example 4 and enabled the testing of the KLT's behavior in the presence of a non-stationary signal.
\section*{Example 1: Decomposition of the Signal}
This simple example shows how the decomposition of a signal $X(t)$ is performed using the KLT.\@ The decomposition starts with the computation of the linear autocorrelation function of the received signal.\@ The next step is to build an autocorrelation Toeplitz matrix and use equation (\ref{eq:7}) to solve a set of linear equations.\@ The result of this equation is the set of eigenvalues and their corresponding eigenfunctions.

The parameters presented in Table 2 were selected for this example.
%Table 2
Figure 1 shows the time representation of the example signal.\@ Because the sine signal component shows up at the identical power level as the noise component, the desired signal can barely be identified in the plot.
Figure 2 presents the computed eigenvalues and the corresponding eigenfunctions of the signal.\@ The plot clearly shows that the first two eigenvalues are significantly higher than all others.\@ The first two eigenfunctions corresponding to these eigenvalues are also characteristic as they show sine-like behavior ofa frequency of one hertz, which relates to the hidden sine in the processed signal.
Moreover, the eigenfunctions allow us to distinguish the non-stochastic content of the signal from the noise content, which is represented by the remaining eigenfunctions.
%Figure 1
\section*{Example 2: Narrowband Signal Detection}
Having illustrated the decomposition of a simple signal in low noise environment using the KLT, the next step is to
investigate thelimits of the KLT technique to detect signals in very strong noise environment.\@ In the following test the KLT performance is compared also against that of an FFT.\@ Note that only one eigenfunction is used to estimate the signal.
However, any number of computed eigenfunctions may be chosen, depending on the level of filtering required.\@ The more eigenfunctions you consider, the more information about the signal (including noise) becomes part of the estimation.\@ Table 3 presents the parameters selected for this example.
From Table 3 we can see that the frequency resolution of the estimated spectrum is different for both methods.\@ The FFT resolution is inversely propor-tional to the signal length while the KLT is inversely proportional to the length of the autocorrelation function (ACF).\@ Because the ACF length is shorter than the signal length, the FFT provides better spectral resolution.
The comparative results of signal detection for FFT and KLT are presented in Figure 3, which clearly shows that the KLT detects a hidden non-stochastic signal with much higher sensitivity than the FFT does.\@ The peak of the hidden signal frequency as detected by the KLT is very high and leaves no doubt whether this is the desired signal or noise.\@ The power spectrum estimates resulting from use ofan FFT technique are much more difficult to interpret.
To complement the overview of this simulation scenario, Figure 4 shows the first 10 eigenvalues (out of a total of 500) ofa signal derived using KLT estimation.\@ Eigenvalues of the signal + noise are represented in black; eigenvalues of only the noise component are indicated in red.\@ As in Figure 2, the first two eigenvalues clearly stick out.\@ Additional simulations could verify that this behavior is typical for a single sine signal hidden in noise.We also want to highlight the fact that a significantly higher
eigenvalue is not the only requirement for the KLT being able to detect a non-stochastic signal correctly.\@ The eigenvalue corresponding to the desired signal also has to be higher than the corresponding eigenvalue of the noise.\@ Although each noise eigenvalue in theory is equal to one in numerical calculations, only the average of all eigenvalues is equal to one.\@ Therefore, individual noise eigenvalues are different from one; consequently, we cannot rely on a threshold equal to one to distinguish between noise and signal.
In Figure 4 the first two noise eigenvalues are clearly not close to one, but higher.\@ By using a longer autocorrelation function, the noise eigenvalues converge to one, but they are still not
uniformly distributed.
\section*{Example 3: Wideband Signal Detection}
The previous example showed that the KLT performs better than the FFT in narrowband signal detection.\@ Next, the KLT is applied to wideband signals.\@ A BPSK-modulated signal serves as the sample signal for detection.
We present the results in the time-frequency domain (see, for example \begin{normalsize}\color{red}Figure 5\end{normalsize}).\@ This allows us to see changes in the estimated spectrums for different instants of a signal observation.
%Figure 5
A fundamental requirement for achieving a proper estimation of the spectrum is the selection of a windowing function that preserves the original spectral characteristics of the signal without introducing significant distortions due to the estimation process.

In the article by G. Heinzel et alia cited in Additional Resources, the HFT90D window type is proposed as optimum for narrowband signals because it determines the exact amplitude of a sinusoidal component.\@ Further analyses are recommended to determine a most appropriate window for wideband signals.\@ Nevertheless and for demonstration purposes the HFT90D window is made use of in the following wideband example.
Compared to other flat-top windows — those window functions'that are as flat as possible in the frequency domain — the HFT90D has a relatively narrow three-decibel bandwidth and very strong side-lobe attenuation.\@ According to G.\@ Heinzel et alia, the recommended overlapping of window functions applied to the datastream is 76 percent.\ \begin{normalsize}\color{red}Table 4\end{normalsize} lists the parameters selected for the wideband signal detection example.
In order to achieve a sufficiently high-frequency resolution of the power spectrum estimation using the KLT technique, the ACF takes 1,000 samples.\@ This, however, comes at the cost of a longer computation time.
Consequently, the KLT needs a high number of eigenfunctions to detect a wideband signal without losing part of the information that describes the non-stochastic signal.\@ In this particular case 50 out of the 1,000 eigenfunctions were chosen.\@ We must keep in mind, however, that the number of eigenfunctions taken to estimate the signals spectrum is indeed the variable KLT parameter that determines the level of filtering.
In the following sections, we present the results of applying KLT,STFT, and Wigner-Ville methods to detect a hidden BPSK signal with an SNR level of -12 decibels.\@ For each method two plots are presented.\@ The first shows the spectrogram of the processed signal, and the second plot shows the power spectrum estimation obtained by averaging the spectrogram.
\section*{KLT}
The top plot in Figure 5 shows the spec-
trogram of the signal computed by the
Karhunen-Loeve Transform. Most of
the power clearly appears to be located
in the lower band of the spectrum, with
much less power at higher frequencies.
However, this spectrogram may not be
precise enough to correctly identify the
BPSK signal. Therefore, the data is aver-
aged over time, with the obtained power
spectrum estimation of the averaged
spectrogram (lower plot) resembling
quite clearly the BPSK(1) signal.
\section*{STFT}
In similar fashion as Figure 5, Figure
6 provides the results of the spectrum
estimation using a Short Time Fourier Transform. The spectrogram as well as the power spectrum show that the STFT method fails to detect the wideband signal.
Still, the lower frequencies have slightly more power compared to the average. However, the noise dominates the signal; so, we cannot recognize the
BPSK(1) signal.
\section*{Wigner-Ville}
Figure 7 shows the results using the Wigner-Ville method. As with STFT, Wigner-Ville fails to detect the wideband signal.
To summarize the preceding simulation results, one can observe that the KLT technique indeed is able to detect wideband signals even in the presence of very strong noise, whereas the STFT and Wigner-Ville methods clearly fail.
Moreover, one can see that, even though
the SNR level is slightly higher com-
pared that used in Example 2 (narrow-
band signal detection), more samples of
the signal were required for estimating
the power spectrum. A wideband signal
carries a lot of information that has to
be observed for a longer period of time
compared to a narrowband signal in
order to recognize its non-stochastic
structure.
\section*{Example 4: Chirp Signal Detection}
We also analyzed a chirp signal with a wide frequency boundary. This type of
signal was chosen to enable us to evaluate the performance of KLT in detecting
a dynamic, non-stationary signal. Table 5 lists the simulation parameters for this test.
In order to be able to achieve a spectrogram estimation with good time resolution, the window length was shortened to 1,000 samples. Also the ACF length was reduced to 500 samples. This setting speeds up the simulation, but reduce the frequency resolution of the KLT spectrum estimation.
Figure 8 shows the KLT spectrogram andthe power spectrum. For a signal with SNR = -12dB the spectrogram is a little frayed but still readable. The KLT is able to detect the chirp signal in the noise.
The challenge here is to define a proper observation window length. It has to be long enough to detect the signal but also short enough to reach the required time resolution. If only a short time period of the signal is considered, the detection process for a chirp signal is similar to the detection of a narrowband signaland, therefore, allows us to rely on only a few initial eigenfunctions.
Although results are not shown here, as in the previous example the STFT and Wigner-Ville methods both failed to detect the chirp signal under the given conditions.
\section*{BAM-KLT:\@ A Step Closer to Fast KLT}
Again, the biggest drawback of the KLT is its complexity and the resulting high computatio-nal burden. As with the Fourier Transform, however, which become popular when its fast implementation (the FFT) became available, the KLT has the potential to experience a similar boost if a fast KLT implementation is discovered.
Maccone has already presented an innovative way of using the KLT, which paves the way towards a faster algorithm. He called this method the BAM-KLT (Bordered Autocorrelation Method KLT), and his paper provides an example of successful sine signal detection using the BAM-KLT to correctly detect a signal hidden in noise (SNR = -23 decibels), while the FFT failed.
This work uncovered the fact that eigenvalues are functions of a final instant T (the same T that appears in the definition of the KL expansion of the final instant of the signal). Using this discovery, Maccone defined “the Final Variance Theorem” expressed by an equation:
\begin{equation}
	\sigma_{X(T)}^2=\sum_{n=1}^{\infty}\pdv{\lambda_n(T)}{T}
	\label{eq:8}
\end{equation}
This theorem states that the variance ofa stochastic process X(t)isequal to the sum of the series of partial derivatives of eigenvalues A (T) with respect to the final instant T Computing a spectrum of such a partial derivative was found to obtain the partial spectrum of the signal. Similar to the KL expansion, the first terms — i.e., the partial derivatives of the eigenvalues — contain the most useful information about the non-stochastic content of the signal.

In theory, using this method in signal processing, one could reduce the computational burden. Instead of calculating both eigenfunctions and eigenvalues, just determining the set of eigenvalues is now sufficient. Additionally, the KLT filtering feature can also be used in this theorem. If only that information kept in the derivative of the first eigenvalue is used, equation (8) can be simplified to:
\begin{equation}
	\sigma_{X(T)}^2 \thickapprox \pdv{\lambda_1(T)}{T}
	\label{eq:9}
\end{equation}
We must point out that BAM-KLT is still a technique that needs to be explored and further tested before it can be used in a predictable manner.
As an example, BAM-KLT shows unwanted behavior at one half of the Nyquist frequency: When using normal frequency representation for the signal spectrum, the signal is displayed at twice its original frequency. This problem was discussed in the paper by Maccone, but not solved.
Based on the parameters in Table 6, the following simulation shows another, very interesting behavior of the eigenvalues beyond those discussed by Maccone, which requires further explanation.
Let's consider only the first two eigenvalues of the signal as a function ofthe time interval and their derivatives. The eigenvalues are plotted in Figure 9. By definition the first eigenvalue always has to be bigger than the second one. But here it seems that the first two eigenvalues become equal at some points. Those represent points of discontinuity of the eigenvalue functions of the time interval. These eigenvalues might also be related to each other, which was not expected.
One possible explanation could lie in the eigenfunctions. They are orthogonal, but they can also have the same spectrum representation (like, for example, sine and cosine). As a consequence, depending on the time span of the signal, one eigenfunction or another has the biggest chance to appear in the signal.
The situation becomes even more complicated when one is processing more complex signals. In that case, one can observe that the eigenvalues interweave not only in pairs but also with further “neighbors.”
This has an effect on the derivatives as well. When computing the FFT ofthe derivatives of the first and the second eigenvalue, the result is a spectrum sine with harmonics, because of the discontinuity of the function. Moreover, the derivatives contain a direct current (DC) component because the mean value of the function is not equal to zero.
This issue is presented here to make users aware of the unexpected behaviour ofthe BAM-KLT and also to show areas for improvement and future investigation.
\section*{BAM-KLT and Wideband Signals}
Because very promising results of singletone detection in a strong noise were presented in Maccone's paper, we thoughtit worthwhile to test the detection capabilities of BAM-KLT for wideband signals. The following results are based on identical test conditions as in the previous tests for estimation of a wideband signal spectrum. First the results ofhidden BPSK(1) signal detection are presented, followed by the detection of a chirp.
Asin the previous examples of BPSK signal detection, Figure 10 presents the result as a spectrogram and the power spectrum estimation. Unfortunately, the BPSK(1) characteristic is not visible and, therefore, the signal detection fails.
A typical behavior of the BAM-KLT is the dominating DC component in both plots. The signal detection capa-
bility of BAM-KLT is much worse than
the one of the original KLT examples
(Figures 5 and 6) and even worse than
what was obtained using the STFT and
Wigner-Ville methods. Obviously, the
BPSK signal cannot be detected by the
BAM-KLT for the given conditions.
\section*{BAM-KLT and Chirp Signal Detection}
BAM-KLT shows a much better perfor-
mance when it comes to chirp signals.
But it is, of course, still not as good as
the original KLT.\@ From the spectro-
gram (Figure 11) it can be seen that the
chirp was detected successfully. None-
theless, a very strong DC component
appears in the spectrum, which could
make the detection of a low-frequency
signal impossible. One can say that the
BAM-KLT is already powerful enough
to detect narrowband signals, excluding
low-frequency signals, which are buried
by strong DC component observed in
the plots.
\section*{Conclusions}
This article shows that the KLT tech-
nique has very high potential and can
outperform the classical signal detec-
tion methods that are used today. The
KLT is equally capable of detecting
both narrowband and wideband sig-
nals, which deserves close attention if
we think of future applications in the
field of GNSS. The simulations
presented here indi-
cate that this trans-
form allows us to
detect more feeble
signals than FFT, STFT, and Wigner-Ville methods can. The main strength of the KLT is its natural feature of adapting to the characteristics of the processed signal. As a result, it allows the filtering ofa non-stochastic signal from noise.
The KLT is also more flexible and configurable than other known methodologies. This permits the user to directly control thelevel of filtering. The remarkable detection capabilities of KLT, however, must be paid for by a high computational burden.
BAM-KLT, which shows excellent detection performance when applied to pure sinusoidal functions, is capable of significantly reducing the computational load. Therefore, some analogies between the BAM-KLT and the FFT can be drawn. Indeed, the introduction of the FFT made it possible to exploit the Fourier Transform in a numerically efficient way.
A similar future could be expected for the BAM-KLT. However, before BAM-KLT or a closely related methodology can be efficiently applied, the spectrum of detectable signals needs to be significantly enlarged. This article shows that the BAM-KLT is not yet capable of unambiguously detecting wideband signals such as BPSKs appearing as noise or interference in a GNSS-like signal. So, further research work needs to be invested in this area. One potential starting point could be to identify relations between the signals to be detected, the windowing function, and the number of characteristic eigenvalues.
In summary, we can say that the KLT
is a very high-performing mathematical
tool and could prove to be of great value.
\end{document} 
